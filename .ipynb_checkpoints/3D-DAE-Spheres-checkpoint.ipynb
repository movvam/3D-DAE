{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pyface/wx/drag_and_drop.py:94: wxPyDeprecationWarning:\n",
      "\n",
      "Call to deprecated item. Use wx.DataFormat instead.\n",
      "\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pyface/ui/wx/clipboard.py:24: wxPyDeprecationWarning:\n",
      "\n",
      "Call to deprecated item. Use wx.DataFormat instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook initialized with png backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Statements\n",
    "#from utils import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from vizz import visualize3D\n",
    "from mayavi import mlab\n",
    "#from utils import Logger\n",
    "from toySphere import sphere\n",
    "import random\n",
    "mlab.init_notebook('png')\n",
    "\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#utils\n",
    "# Custom dataloader for 3D spheres dataset \n",
    "class ToySpheres(Dataset):\n",
    "\n",
    "    def __init__(self, shape, seed, transform=None):\n",
    "        random.seed(seed)\n",
    "        self.data_dir = []\n",
    "        self.dataShape = shape\n",
    "        print('Creating training data...')\n",
    "        for _ in range(shape[0]):\n",
    "            s_x = random.randint(-shape[2]//2 + 2, shape[2]//2 - 2)\n",
    "            s_y = random.randint(-shape[3]//2 + 2, shape[3]//2 - 2)\n",
    "            s_z = random.randint(-shape[4]//2 + 2, shape[4]//2 - 2)\n",
    "            s_r = random.uniform(1.1, 8.0)\n",
    "            self.data_dir.append((s_x, s_y, s_z, s_r))\n",
    "        print('Complete!')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_dir)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        params = self.data_dir[idx]\n",
    "        model = np.expand_dims(sphere(self.dataShape[2], self.dataShape[3], self.dataShape[4],\n",
    "                                      params[0],\n",
    "                                      params[1],\n",
    "                                      params[2],\n",
    "                                      params[3]), axis=0)\n",
    "        if self.transform:\n",
    "            model = self.transform(model)\n",
    "        return torch.from_numpy(model)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#for one-hot encoding\n",
    "def to_categorical(y, num_classes=None, dtype='float32'):\n",
    "    \"\"\"Converts a class vector (integers) to binary class matrix.\n",
    "    E.g. for use with categorical_crossentropy.\n",
    "    # Arguments\n",
    "        y: class vector to be converted into a matrix\n",
    "            (integers from 0 to num_classes).\n",
    "        num_classes: total number of classes.\n",
    "        dtype: The data type expected by the input, as a string\n",
    "            (`float32`, `float64`, `int32`...)\n",
    "    # Returns\n",
    "        A binary matrix representation of the input. The classes axis\n",
    "        is placed last.\n",
    "    # Example\n",
    "    ```python\n",
    "    # Consider an array of 5 labels out of a set of 3 classes {0, 1, 2}:\n",
    "    > labels\n",
    "    array([0, 2, 1, 2, 0])\n",
    "    # `to_categorical` converts this into a matrix with as many\n",
    "    # columns as there are classes. The number of rows\n",
    "    # stays the same.\n",
    "    > to_categorical(labels)\n",
    "    array([[ 1.,  0.,  0.],\n",
    "           [ 0.,  0.,  1.],\n",
    "           [ 0.,  1.,  0.],\n",
    "           [ 0.,  0.,  1.],\n",
    "           [ 1.,  0.,  0.]], dtype=float32)\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.array(y, dtype='int')\n",
    "    input_shape = y.shape\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1])\n",
    "    y = y.ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes), dtype=dtype)\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    output_shape = input_shape + (num_classes,)\n",
    "    categorical = np.reshape(categorical, output_shape)\n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1)    # reproducible\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 128\n",
    "EMBEDDING_SIZE = (2, 2, 2)\n",
    "NOISE_VAL = 0.2\n",
    "LR = 0.001         # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training data...\n",
      "Complete!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'blender': 'blender'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-424992fd39e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtest_sphere\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mvisualize3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sphere\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sample\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# test_sphere = dataset[12].detach().numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code/3D-DAE/vizz.py\u001b[0m in \u001b[0;36mvisualize3D\u001b[0;34m(voxel_data, title, thresh, percentile, plot)\u001b[0m\n\u001b[1;32m     36\u001b[0m                          \u001b[0;34m'--destfile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                          '--voxels', voxel_string]\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblender_arguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    707\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1342\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'blender': 'blender'"
     ]
    }
   ],
   "source": [
    "dataset = ToySpheres((6000, 1, 16, 16, 16), 1)\n",
    "\n",
    "# Create loader with data, so that we can iterate over it\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "# Num batches\n",
    "num_batches = len(train_loader)\n",
    "\n",
    "#test visualization\n",
    "for index in range(20):\n",
    "    test_sphere = np.squeeze(dataset[index].detach().numpy())\n",
    "    visualize3D(test_sphere, title=\"sample\" + str(index), thresh=0.1)\n",
    "    plt.show()\n",
    "# test_sphere = dataset[12].detach().numpy()\n",
    "# visualize3D(test_sphere, color=(0,1,1), thresh= 0.1)\n",
    "# visualize3D(test_sphere, color=(0,1,0), thresh= 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define AutoEncoder class\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, 3, stride=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool3d(2, stride=2),\n",
    "            nn.Conv3d(64, 32, 3, stride=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool3d(2, stride=2),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(32, 64, 3, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose3d(64, 32, 3, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose3d(32, 4, 3, stride=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose3d(4, 1, 4, stride=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, val):\n",
    "        encoded = self.encoder(val)\n",
    "        print(encoded.shape)\n",
    "        decoded = self.decoder(encoded)\n",
    "        print(decoded.shape)\n",
    "        return encoded, decoded\n",
    "        \n",
    "    def encode(self, val):\n",
    "        val = self.encoder(val)\n",
    "        return val.cpu().data\n",
    "\n",
    "    def decode(self, val):\n",
    "        val = self.decoder(val)\n",
    "        return val.cpu().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AutoEncoder()\n",
    "\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)\n",
    "#d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "loss_func = nn.BCELoss()\n",
    "#loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for step, (x) in enumerate(train_loader):\n",
    "        print(step)\n",
    "        # batch x, shape (batch, 28, 28)\n",
    "        b_x = x + NOISE_VAL * torch.rand_like(x) / (1.0 + NOISE_VAL) # Renormalize with added noise\n",
    "\n",
    "        encoded, decoded = autoencoder(b_x)\n",
    "\n",
    "        loss = loss_func(decoded, x)        # mean square error\n",
    "        optimizer.zero_grad()               # clear gradients for this training step\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.numpy())\n",
    "\n",
    "            # plotting decoded image (second row)\n",
    "            #_, decoded_data = autoencoder(view_data)\n",
    "#             decoded_data = np.reshape(decoded_data.data.numpy()[0], (4, 16, 16, 16))\n",
    "#             s = visualize3D(decoded_data, color=(0, 1, 1), percentile=0.85)\n",
    "#             s\n",
    "#             # initialize figure\n",
    "#             f, a = plt.subplots(2, N_TEST_IMG, figsize=(5, 2))\n",
    "\n",
    "#             for i in range(N_TEST_IMG):\n",
    "#                 a[0][i].imshow(np.reshape(view_data.data.numpy()[i], (28, 28)), cmap='gray'); a[0][i].set_xticks(()); a[0][i].set_yticks(())\n",
    "#                 a[1][i].clear()\n",
    "#                 a[1][i].imshow(np.reshape(decoded_data.data.numpy()[i], (28, 28)), cmap='gray')\n",
    "#                 a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
    "#             plt.draw(); plt.pause(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
